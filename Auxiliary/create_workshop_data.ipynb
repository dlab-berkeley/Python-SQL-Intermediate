{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf28a43",
   "metadata": {},
   "source": [
    "# Customer Dataset Generation for SQL Workshop\n",
    "\n",
    "This notebook generates a focused customer dataset that includes exactly the fields needed to demonstrate the SQL concepts in the workshop. The data structure is deliberately kept simple and includes only what's necessary for the workshop examples.\n",
    "\n",
    "Generated fields:\n",
    "- name (TEXT) - For string operations and pattern matching\n",
    "- city (TEXT) - For location-based queries and string concatenation\n",
    "- country (TEXT) - For working with codes and IN operators\n",
    "- items_purchased (INTEGER) - For numeric operations and range filters\n",
    "- price_per_item (REAL) - For calculations and NULL handling\n",
    "- last_purchase (TEXT) - For date functions and filtering\n",
    "- account_balance (REAL) - For additional numeric comparisons\n",
    "\n",
    "The generated data will be exported as:\n",
    "1. `customers.csv` - CSV format\n",
    "2. `customers.sqlite` - SQLite database for workshop queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3690c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5293556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate minimal sample data that covers all concepts\n",
    "n_customers = 25  # Enough for examples, not too many\n",
    "\n",
    "# Sample data for each field - just enough variety for meaningful examples\n",
    "names = [\n",
    "    \"John Smith\", \"Maria Garcia\", \"Li Wei\", \"Emma Brown\", \"Ahmed Hassan\",  # English, Spanish, Chinese, English, Arabic\n",
    "    \"Sarah Johnson\", \"Carlos Rodriguez\", \"Anna Kowalski\", \"James Wilson\", \"Yuki Tanaka\",  # English, Spanish, Polish, English, Japanese\n",
    "    \"Elena Popov\", \"Michel Dubois\", \"Sofia Santos\", \"Lars Andersen\", \"Aisha Patel\",  # Russian, French, Portuguese, Danish, Indian\n",
    "    \"Diego Martinez\", \"Lucy Chen\", \"Ivan Petrov\", \"Mary Williams\", \"Raj Kumar\",  # Spanish, Chinese, Russian, English, Indian\n",
    "    \"Hans Schmidt\", \"Isabella Silva\", \"Fatima Al-Said\", \"Jun Park\", \"Anna Ivanova\"  # German, Portuguese, Arabic, Korean, Russian\n",
    "]\n",
    "\n",
    "# Cities - mix of major cities with good geographic distribution\n",
    "cities = [\n",
    "    \"New York\", \"London\", \"Tokyo\", \"Paris\", \"Sydney\",  # Major global cities\n",
    "    \"Berlin\", \"Mumbai\", \"SÃ£o Paulo\", \"Toronto\", \"Shanghai\",  # More major cities\n",
    "    \"Madrid\", \"Moscow\", \"Dubai\", None, \"Mexico City\",  # Some NULLs\n",
    "    \"Amsterdam\", \"Cairo\", \"Stockholm\", None, \"Los Angeles\",  # More NULLs\n",
    "    \"Rome\", \"Hong Kong\", \"Istanbul\", \"Seoul\", \"Bangkok\"  # Additional variety\n",
    "]\n",
    "\n",
    "# Countries - good mix for grouping examples\n",
    "countries = [\n",
    "    \"US\", \"GB\", \"JP\", \"FR\", \"AU\",  # 5 major countries\n",
    "    \"DE\", \"IN\", \"BR\", \"CA\", \"CN\",  # 5 more countries\n",
    "    \"ES\", \"RU\", \"AE\", None, \"MX\",  # Some NULLs\n",
    "    \"NL\", \"EG\", \"SE\", None, \"US\",  # More NULLs, plus some duplicates\n",
    "    \"IT\", \"HK\", \"TR\", \"KR\", \"TH\"   # Additional variety\n",
    "]\n",
    "\n",
    "# Generate numeric data as lists for easier NULL handling\n",
    "items_purchased = [np.random.randint(1, 20) for _ in range(n_customers)]\n",
    "price_per_item = [round(np.random.uniform(10.0, 100.0), 2) for _ in range(n_customers)]\n",
    "account_balance = [round(np.random.uniform(100.0, 1000.0), 2) for _ in range(n_customers)]\n",
    "\n",
    "# Generate last_purchase dates - 12 months is enough for examples\n",
    "base_date = datetime(2024, 1, 1)\n",
    "last_purchases = []\n",
    "for i in range(n_customers):\n",
    "    days = np.random.randint(0, 365)\n",
    "    date = base_date + timedelta(days=days)\n",
    "    last_purchases.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "# Add NULL values strategically\n",
    "null_indices = np.random.choice(n_customers, 6, replace=False)  # 6 NULLs total\n",
    "for idx in null_indices[:2]:\n",
    "    items_purchased[idx] = None\n",
    "for idx in null_indices[2:4]:\n",
    "    price_per_item[idx] = None\n",
    "for idx in null_indices[4:]:\n",
    "    account_balance[idx] = None\n",
    "for idx in null_indices[:3]:  # Some NULL dates\n",
    "    last_purchases[idx] = None\n",
    "\n",
    "# Create the data dictionary\n",
    "data = {\n",
    "    'name': names,\n",
    "    'city': cities,\n",
    "    'country': countries,\n",
    "    'items_purchased': items_purchased,\n",
    "    'price_per_item': price_per_item,\n",
    "    'last_purchase': last_purchases,\n",
    "    'account_balance': account_balance\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aaa417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the generated dataset:\n",
      "\n",
      "First few rows:\n",
      "           name      city country  items_purchased  price_per_item  \\\n",
      "0    John Smith  New York      US              NaN           56.28   \n",
      "1  Maria Garcia    London      GB             15.0             NaN   \n",
      "2        Li Wei     Tokyo      JP             11.0           14.18   \n",
      "3    Emma Brown     Paris      FR              8.0           64.68   \n",
      "4  Ahmed Hassan    Sydney      AU              7.0           25.35   \n",
      "\n",
      "  last_purchase  account_balance  \n",
      "0          None           945.55  \n",
      "1    2024-08-18           905.34  \n",
      "2    2024-02-10           638.11  \n",
      "3    2024-01-28           929.69  \n",
      "4    2024-05-14           179.64  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   name             25 non-null     object \n",
      " 1   city             23 non-null     object \n",
      " 2   country          23 non-null     object \n",
      " 3   items_purchased  23 non-null     float64\n",
      " 4   price_per_item   23 non-null     float64\n",
      " 5   last_purchase    22 non-null     object \n",
      " 6   account_balance  23 non-null     float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 1.5+ KB\n",
      "None\n",
      "\n",
      "Dataset exported to customers.csv\n",
      "Dataset exported to customers.sqlite\n",
      "\n",
      "Value ranges in the dataset:\n",
      "\n",
      "items_purchased:\n",
      "  Min: 1.00\n",
      "  Max: 19.00\n",
      "  Null count: 2\n",
      "\n",
      "price_per_item:\n",
      "  Min: 13.09\n",
      "  Max: 97.26\n",
      "  Null count: 2\n",
      "\n",
      "account_balance:\n",
      "  Min: 104.97\n",
      "  Max: 988.20\n",
      "  Null count: 2\n"
     ]
    }
   ],
   "source": [
    "# Show the first few rows and dataset info\n",
    "print(\"Preview of the generated dataset:\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = 'customers.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nDataset exported to {csv_path}\")\n",
    "\n",
    "# Export to SQLite\n",
    "sqlite_path = 'customers.sqlite'\n",
    "with sqlite3.connect(sqlite_path) as conn:\n",
    "    df.to_sql('customers', conn, if_exists='replace', index=False)\n",
    "print(f\"Dataset exported to {sqlite_path}\")\n",
    "\n",
    "# Print value ranges to confirm suitability for workshop examples\n",
    "print(\"\\nValue ranges in the dataset:\")\n",
    "numeric_cols = ['items_purchased', 'price_per_item', 'account_balance']\n",
    "for col in numeric_cols:\n",
    "    non_null = df[df[col].notnull()][col]\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {non_null.min():.2f}\")\n",
    "    print(f\"  Max: {non_null.max():.2f}\")\n",
    "    print(f\"  Null count: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916568a",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "\n",
    "The generated dataset includes a minimal set of records and fields needed for the SQL workshop examples:\n",
    "\n",
    "| Column | Type | Description | Example | Notes |\n",
    "|--------|------|-------------|---------|-------|\n",
    "| name | TEXT | Customer's full name | \"John Smith\" | Never NULL, 25 unique names |\n",
    "| city | TEXT | Customer's city | \"New York\" | 2 NULL values (8%) |\n",
    "| country | TEXT | Country code | \"US\" | 2 NULL values (8%) |\n",
    "| items_purchased | INTEGER | Number of items purchased | 5 | 2 NULL values (8%), Range: 1-20 |\n",
    "| price_per_item | REAL | Price per item in USD | 45.99 | 2 NULL values (8%), Range: $10-$100 |\n",
    "| last_purchase | TEXT | Date of last purchase | \"2024-06-15\" | 3 NULL values (12%), Range: 2024 dates |\n",
    "| account_balance | REAL | Account balance in USD | 523.45 | 2 NULL values (8%), Range: $100-$1000 |\n",
    "\n",
    "This minimal dataset supports all SQL concepts in the workshop:\n",
    "\n",
    "1. **Basic Queries**\n",
    "   - SELECT and column selection\n",
    "   - Column aliases\n",
    "   - String operations (name, city, country)\n",
    "   - Numeric calculations (items_purchased Ã price_per_item)\n",
    "   - Date operations (last_purchase)\n",
    "\n",
    "2. **WHERE Clause**\n",
    "   - Basic comparisons (>, <, =, etc.)\n",
    "   - Pattern matching (LIKE with name, city)\n",
    "   - Multiple conditions (AND, OR)\n",
    "   - NULL handling (IS NULL, IS NOT NULL)\n",
    "   - Range checks (BETWEEN)\n",
    "\n",
    "3. **Sorting and Pagination**\n",
    "   - ORDER BY (all columns)\n",
    "   - Multiple sort columns\n",
    "   - LIMIT/OFFSET (25 rows is enough)\n",
    "\n",
    "4. **Aggregates and Grouping**\n",
    "   - Basic aggregates (COUNT, SUM, AVG, etc.)\n",
    "   - GROUP BY (country, city, month)\n",
    "   - HAVING clause\n",
    "   - NULL handling in groups\n",
    "\n",
    "The data has been minimized while ensuring:\n",
    "- Enough rows for pagination (25)\n",
    "- Sufficient groups for aggregation (20+ cities, 15+ countries)\n",
    "- Strategic NULL values\n",
    "- Reasonable numeric ranges\n",
    "- Good date distribution (1 year)\n",
    "- Diverse text data for pattern matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca734e2c",
   "metadata": {},
   "source": [
    "## 1. Creating Sample Data with NULL Values\n",
    "\n",
    "First, we'll create a sample customer dataset that includes NULL values in several columns. This will help us demonstrate various NULL handling scenarios. We'll:\n",
    "\n",
    "1. Import required libraries\n",
    "2. Create a DataFrame with NULL values\n",
    "3. Create an SQLite database\n",
    "4. Load our data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8daa6651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Customer Data:\n",
      "            name      city country     phone  items_purchased  price_per_item\n",
      "0     John Smith  New York      US  555-0101              3.0            10.0\n",
      "1  Sarah Johnson   Chicago      US      None              2.0            15.0\n",
      "2    Michael Lee   Seattle      US  555-0303              NaN            20.0\n",
      "3     Emma Davis      None      US  555-0404              1.0             NaN\n",
      "4   David Wilson    Boston      US      None              4.0            12.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create sample customer data with NULL values\n",
    "customer_data = {\n",
    "    'name': ['John Smith', 'Sarah Johnson', 'Michael Lee', 'Emma Davis', 'David Wilson'],\n",
    "    'city': ['New York', 'Chicago', 'Seattle', None, 'Boston'],\n",
    "    'country': ['US', 'US', 'US', 'US', 'US'],\n",
    "    'phone': ['555-0101', None, '555-0303', '555-0404', None],\n",
    "    'items_purchased': [3, 2, None, 1, 4],\n",
    "    'price_per_item': [10.0, 15.0, 20.0, None, 12.0]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "customers_df = pd.DataFrame(customer_data)\n",
    "\n",
    "# Create SQLite database in memory\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "customers_df.to_sql('customers', engine, index=False)\n",
    "\n",
    "print(\"Sample Customer Data:\")\n",
    "print(customers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac292bb",
   "metadata": {},
   "source": [
    "## 2. Common Mistake: Using Equality with NULL\n",
    "\n",
    "A common mistake when working with NULL values is trying to use the equality operator (`=`). Let's see why this doesn't work:\n",
    "\n",
    "* `NULL` represents an unknown value\n",
    "* Comparing anything with an unknown value results in an unknown result\n",
    "* `WHERE column = NULL` will never match any rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e8ed3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to find customers with NULL city using incorrect method (WHERE city = NULL):\n",
      "\n",
      "Results:\n",
      "Empty DataFrame\n",
      "Columns: [name, city]\n",
      "Index: []\n",
      "\n",
      "Note: No results were returned because '= NULL' never evaluates to TRUE\n"
     ]
    }
   ],
   "source": [
    "# Incorrect query - trying to find customers with NULL city\n",
    "incorrect_query = \"\"\"\n",
    "SELECT name, city\n",
    "FROM customers\n",
    "WHERE city = NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Attempting to find customers with NULL city using incorrect method (WHERE city = NULL):\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(incorrect_query, engine))\n",
    "print(\"\\nNote: No results were returned because '= NULL' never evaluates to TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc03a7",
   "metadata": {},
   "source": [
    "## 3. Correct Approach: Using IS NULL\n",
    "\n",
    "The correct way to check for NULL values is using the `IS NULL` operator. This operator is specifically designed to handle the special nature of NULL values. Let's see how it works:\n",
    "\n",
    "* `IS NULL` checks if a value is NULL\n",
    "* `IS NOT NULL` checks if a value is not NULL\n",
    "* These operators work as expected with NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c5f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding customers with NULL city using correct method (WHERE city IS NULL):\n",
      "\n",
      "Results:\n",
      "         name  city\n",
      "0  Emma Davis  None\n",
      "\n",
      "Finding customers with non-NULL city (WHERE city IS NOT NULL):\n",
      "\n",
      "Results:\n",
      "            name      city\n",
      "0     John Smith  New York\n",
      "1  Sarah Johnson   Chicago\n",
      "2    Michael Lee   Seattle\n",
      "3   David Wilson    Boston\n"
     ]
    }
   ],
   "source": [
    "# Correct query - finding customers with NULL city\n",
    "correct_query = \"\"\"\n",
    "SELECT name, city\n",
    "FROM customers\n",
    "WHERE city IS NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Finding customers with NULL city using correct method (WHERE city IS NULL):\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(correct_query, engine))\n",
    "\n",
    "# Also demonstrate IS NOT NULL\n",
    "not_null_query = \"\"\"\n",
    "SELECT name, city\n",
    "FROM customers\n",
    "WHERE city IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nFinding customers with non-NULL city (WHERE city IS NOT NULL):\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(not_null_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27d3a3",
   "metadata": {},
   "source": [
    "## 4. Advanced NULL Handling with COALESCE\n",
    "\n",
    "COALESCE is a powerful function for handling NULL values in SQL. It returns the first non-NULL value in a list of expressions. Common uses include:\n",
    "\n",
    "* Providing default values for NULL fields\n",
    "* Creating derived columns that handle NULL values gracefully\n",
    "* Filtering for records with any NULL value\n",
    "\n",
    "Let's explore some practical examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68027b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using COALESCE to replace NULL values with defaults:\n",
      "\n",
      "Results:\n",
      "            name              city  items_purchased  price_per_item\n",
      "0     John Smith          New York              3.0            10.0\n",
      "1  Sarah Johnson           Chicago              2.0            15.0\n",
      "2    Michael Lee           Seattle              0.0            20.0\n",
      "3     Emma Davis  Location Unknown              1.0             0.0\n",
      "4   David Wilson            Boston              4.0            12.0\n",
      "\n",
      "Finding customers with missing contact information:\n",
      "\n",
      "Results:\n",
      "            name          city     phone\n",
      "0  Sarah Johnson       Chicago  No Phone\n",
      "1     Emma Davis  Unknown City  555-0404\n",
      "2   David Wilson        Boston  No Phone\n",
      "\n",
      "Calculating total value with NULL handling:\n",
      "\n",
      "Results:\n",
      "            name  total_value\n",
      "0   David Wilson         48.0\n",
      "1     John Smith         30.0\n",
      "2  Sarah Johnson         30.0\n",
      "3    Michael Lee          0.0\n",
      "4     Emma Davis          0.0\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Using COALESCE for default values\n",
    "coalesce_query = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    COALESCE(city, 'Location Unknown') as city,\n",
    "    COALESCE(items_purchased, 0) as items_purchased,\n",
    "    COALESCE(price_per_item, 0.0) as price_per_item\n",
    "FROM customers\n",
    "\"\"\"\n",
    "\n",
    "print(\"Using COALESCE to replace NULL values with defaults:\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(coalesce_query, engine))\n",
    "\n",
    "# Example 2: Finding customers with any missing contact information\n",
    "missing_info_query = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    COALESCE(city, 'Unknown City') as city,\n",
    "    COALESCE(phone, 'No Phone') as phone\n",
    "FROM customers\n",
    "WHERE city IS NULL \n",
    "   OR phone IS NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nFinding customers with missing contact information:\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(missing_info_query, engine))\n",
    "\n",
    "# Example 3: Calculating total value with NULL handling\n",
    "total_value_query = \"\"\"\n",
    "SELECT \n",
    "    name,\n",
    "    COALESCE(items_purchased, 0) * COALESCE(price_per_item, 0) as total_value\n",
    "FROM customers\n",
    "ORDER BY total_value DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nCalculating total value with NULL handling:\")\n",
    "print(\"\\nResults:\")\n",
    "print(pd.read_sql_query(total_value_query, engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027fdf4",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "When working with NULL values in SQL, remember:\n",
    "\n",
    "1. **Never use `= NULL` or `!= NULL`**\n",
    "   * Always use `IS NULL` or `IS NOT NULL` instead\n",
    "\n",
    "2. **Use COALESCE for default values**\n",
    "   * Helps avoid NULL propagation in calculations\n",
    "   * Makes reports more readable\n",
    "   * Ensures consistent data handling\n",
    "\n",
    "3. **Consider NULL in your database design**\n",
    "   * Decide whether columns should allow NULL values\n",
    "   * Use NOT NULL constraints when appropriate\n",
    "   * Document your NULL handling strategy\n",
    "\n",
    "4. **Be careful with aggregate functions**\n",
    "   * Most aggregate functions ignore NULL values\n",
    "   * COUNT(*) includes NULL values, COUNT(column) excludes them\n",
    "   * Use COALESCE when you need to include NULL values in calculations\n",
    "\n",
    "These practices will help you handle NULL values correctly and write more robust SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729f75b7-83d9-4306-a0e2-c701cdfd15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nIncome Data Preview:\n",
      "Total records: 22\n",
      "Unique people: 15\n",
      "People in both tables: 10\n",
      "Income-only people: 5\n",
      "Customers-only people: 15\n",
      "\\nFirst 10 income records:\n",
      "            name income_source  amount        day\n",
      "0     John Smith        Salary  3000.0     Monday\n",
      "1     John Smith     Freelance   500.0     Friday\n",
      "2   Maria Garcia        Salary  2500.0     Monday\n",
      "3   Maria Garcia         Bonus  1000.0     Friday\n",
      "4         Li Wei        Salary     NaN     Monday\n",
      "5         Li Wei    Investment   200.0  Wednesday\n",
      "6   Ahmed Hassan        Salary  3500.0     Monday\n",
      "7   Ahmed Hassan    Consulting  1500.0    Tuesday\n",
      "8   Ahmed Hassan        Rental   800.0   Thursday\n",
      "9  Sarah Johnson        Salary     NaN     Monday\n",
      "\\nIncome data exported to income.csv\n",
      "\\nTables in database: ['customers', 'income']\n",
      "\\nIncome by day (for pivot examples):\n",
      "day\n",
      "Monday       11\n",
      "Friday        3\n",
      "Wednesday     3\n",
      "Thursday      2\n",
      "Tuesday       2\n",
      "Saturday      1\n",
      "Name: name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Generate income data for pivot/melt and JOIN examples\n",
    "# This complements the customers table with income information\n",
    "\n",
    "# Strategic selection of names:\n",
    "# - Some customers have multiple income sources (John Smith, Maria Garcia, Li Wei)\n",
    "# - Some customers have no income data (Emma Brown, Carlos Rodriguez, many others)\n",
    "# - Some people have income but aren't customers (Jennifer Wilson, Robert Taylor, Amanda Lee)\n",
    "\n",
    "income_records = []\n",
    "\n",
    "# Customers with multiple income sources\n",
    "multi_income_customers = [\n",
    "    ('John Smith', [('Salary', 3000, 'Monday'), ('Freelance', 500, 'Friday')]),\n",
    "    ('Maria Garcia', [('Salary', 2500, 'Monday'), ('Bonus', 1000, 'Friday')]),\n",
    "    ('Li Wei', [('Salary', 4000, 'Monday'), ('Investment', 200, 'Wednesday')]),\n",
    "    ('Ahmed Hassan', [('Salary', 3500, 'Monday'), ('Consulting', 1500, 'Tuesday'), ('Rental', 800, 'Thursday')]),\n",
    "    ('Sarah Johnson', [('Salary', 2800, 'Monday'), ('Teaching', 400, 'Wednesday')])\n",
    "]\n",
    "\n",
    "for name, sources in multi_income_customers:\n",
    "    for source, amount, day in sources:\n",
    "        income_records.append({\n",
    "            'name': name,\n",
    "            'income_source': source,\n",
    "            'amount': amount,\n",
    "            'day': day\n",
    "        })\n",
    "\n",
    "# Customers with single income source\n",
    "single_income_customers = [\n",
    "    ('Yuki Tanaka', 'Salary', 3200, 'Monday'),\n",
    "    ('Elena Popov', 'Pension', 1800, 'Friday'),\n",
    "    ('Lars Andersen', 'Salary', 4500, 'Monday'),\n",
    "    ('Diego Martinez', 'Salary', 2700, 'Monday'),\n",
    "    ('Mary Williams', 'Part-time', 1200, 'Tuesday')\n",
    "]\n",
    "\n",
    "for name, source, amount, day in single_income_customers:\n",
    "    income_records.append({\n",
    "        'name': name,\n",
    "        'income_source': source,\n",
    "        'amount': amount,\n",
    "        'day': day\n",
    "    })\n",
    "\n",
    "# People with income who are NOT in the customers table\n",
    "non_customers = [\n",
    "    ('Jennifer Wilson', 'Salary', 3100, 'Monday'),\n",
    "    ('Robert Taylor', 'Salary', 2900, 'Monday'),\n",
    "    ('Robert Taylor', 'Uber', 600, 'Saturday'),\n",
    "    ('Amanda Lee', 'Freelance', 2200, 'Thursday'),\n",
    "    ('Michael Brown', 'Salary', 3400, 'Monday'),\n",
    "    ('Patricia Davis', 'Consulting', 4000, 'Wednesday')\n",
    "]\n",
    "\n",
    "for name, source, amount, day in non_customers:\n",
    "    income_records.append({\n",
    "        'name': name,\n",
    "        'income_source': source,\n",
    "        'amount': amount,\n",
    "        'day': day\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "income_df = pd.DataFrame(income_records)\n",
    "\n",
    "# Add some NULL values for demonstration\n",
    "null_indices = np.random.choice(len(income_df), 2, replace=False)\n",
    "for idx in null_indices:\n",
    "    income_df.loc[idx, 'amount'] = None\n",
    "\n",
    "# Display the income data\n",
    "print(\"\\\\nIncome Data Preview:\")\n",
    "print(f\"Total records: {len(income_df)}\")\n",
    "print(f\"Unique people: {income_df['name'].nunique()}\")\n",
    "print(f\"People in both tables: {len(set(income_df['name'].unique()) & set(df['name'].unique()))}\")\n",
    "print(f\"Income-only people: {len(set(income_df['name'].unique()) - set(df['name'].unique()))}\")\n",
    "print(f\"Customers-only people: {len(set(df['name'].unique()) - set(income_df['name'].unique()))}\")\n",
    "print(\"\\\\nFirst 10 income records:\")\n",
    "print(income_df.head(10))\n",
    "\n",
    "# Export to CSV\n",
    "income_csv_path = 'income.csv'\n",
    "income_df.to_csv(income_csv_path, index=False)\n",
    "print(f\"\\\\nIncome data exported to {income_csv_path}\")\n",
    "\n",
    "# Add to SQLite database\n",
    "with sqlite3.connect(sqlite_path) as conn:\n",
    "    income_df.to_sql('income', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Verify both tables exist\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(f\"\\\\nTables in database: {[t[0] for t in tables]}\")\n",
    "\n",
    "# Show income distribution for pivot examples\n",
    "print(\"\\\\nIncome by day (for pivot examples):\")\n",
    "day_summary = income_df.groupby('day')['name'].count().sort_values(ascending=False)\n",
    "print(day_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
